{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Some simple forecasting methods\n",
    "\n",
    "We are going to start with some really simple models to predict time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/72/x6_kg98117nd5xkqbx_bl3dc0000gn/T/ipykernel_41835/1257075650.py:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  .assign(Date=pd.to_datetime(d.Quarter.str.replace(' ', '')))\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv('data/aus_production.csv')\n",
    "aus_production = (\n",
    "    d\n",
    "    .assign(Date=pd.to_datetime(d.Quarter.str.replace(' ', '')))\n",
    "    .pipe(compute, lambda x: dict(Year=x.Date.dt.year))\n",
    "    .set_index('Date', drop=False)\n",
    "    .drop(columns='Date Year'.split())\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bricks = aus_production['1970-01-01':'2004-01-01']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SimpleTSModel:\n",
    "    \"\"\"Simple TS model base class.\"\"\"\n",
    "    def __init__(self, y):\n",
    "        \"\"\"Determine y data and sampling frequency.\"\"\"\n",
    "        if not hasattr(y, 'index'):\n",
    "            y = pd.Series(y)\n",
    "        if hasattr(y.index, 'inferred_freq'):\n",
    "            self.y = y.asfreq(y.index.inferred_freq)\n",
    "            self.freq = self.y.index.freq\n",
    "        else:\n",
    "            self.y = y.copy()\n",
    "            self.freq = None\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Nothing to do here, but in other libraries this is a method that does things.\"\"\"\n",
    "        return self\n",
    "\n",
    "    def forecast(self, dt=None, end=None, periods=None):\n",
    "        \"\"\"Make a forward-looking prediction.\"\"\"\n",
    "        assert sum([dt is None, end is None, periods is None]) == 2\n",
    "        tmax = self.y.index.max()\n",
    "        if dt is not None:\n",
    "            end = tmax + (pd.to_timedelta(dt) if self.freq else dt)\n",
    "        elif end is not None:\n",
    "            end = pd.to_datetime(end) if self.freq else end\n",
    "        elif periods is not None:\n",
    "            end = tmax + periods * (self.freq or 1)\n",
    "        return self.predict(tmax + 1 * (self.freq or 1), end)\n",
    "\n",
    "    def _normalize_times(self, start, end):\n",
    "        \"\"\"Do some tedious datetime manipulation.\"\"\"\n",
    "        Y = self.y\n",
    "        t0 = Y.index.min()\n",
    "        if start is None:\n",
    "            start = t0\n",
    "        if end is None:\n",
    "            end = Y.index.max()\n",
    "        if self.freq is not None:\n",
    "            start = pd.to_datetime(start)\n",
    "            end = pd.to_datetime(end)\n",
    "        if self.freq:\n",
    "            index = pd.date_range(t0, end, freq=self.freq)\n",
    "        else:\n",
    "            index = np.arange(t0, end+1)\n",
    "        return start, end, index\n",
    "\n",
    "class TSMean(SimpleTSModel):\n",
    "    \"\"\"The future will look like the average of the past.\"\"\"\n",
    "    def predict(self, start=None, end=None):\n",
    "        # value is always the mean\n",
    "        Y = self.y\n",
    "        start, end, index = self._normalize_times(start, end)\n",
    "        m = Y.mean()\n",
    "        out = pd.Series(m, index=index)\n",
    "        out = out.loc[start:].copy()\n",
    "        return out\n",
    "\n",
    "class TSNaive(SimpleTSModel):\n",
    "    \"\"\"Tomorrow will look like today.\"\"\"\n",
    "    def predict(self, start=None, end=None):\n",
    "        # tomorrow probably same as today\n",
    "        Y = self.y\n",
    "        start, end, index = self._normalize_times(start, end)\n",
    "        out = pd.Series(np.nan, index=index)\n",
    "        out.loc[:Y.index.max()] = Y\n",
    "        out = out.shift(1)\n",
    "        out.loc[Y.index.max():] = Y.iloc[-1]\n",
    "        out = out.loc[start:].copy()\n",
    "        return out.copy()\n",
    "\n",
    "class TSNaiveSeasonal(SimpleTSModel):\n",
    "    \"\"\"Next year will fluctuate the same way as this year.\"\"\"\n",
    "    def __init__(self, y, lag):\n",
    "        super(TSNaiveSeasonal, self).__init__(y)\n",
    "        self.lag = lag\n",
    "        assert self.y.index.min() + lag * (self.freq or 1) < self.y.index.max(), \\\n",
    "            'lag must be less than input timeseries'\n",
    "\n",
    "    def predict(self, start=None, end=None):\n",
    "        # tomorrow probably same as this time last year/month/whatever\n",
    "        Y, lag = self.y, self.lag\n",
    "        start, end, index = self._normalize_times(start, end)\n",
    "        out = pd.Series(np.nan, index=index)\n",
    "        out.loc[:Y.index.max()] = Y\n",
    "        out = out.shift(lag)\n",
    "        i = 0\n",
    "        while np.isnan(out.iloc[-1]):\n",
    "            mask = out.isna()\n",
    "            out[mask] = out.shift(lag)[mask]\n",
    "            i += 1\n",
    "        out = out.loc[start:].copy()\n",
    "        return out.copy()\n",
    "\n",
    "class TSDrift(SimpleTSModel):\n",
    "    \"\"\"Draw a line from t=0 thru today, and extrapolate to tomorrow.\"\"\"\n",
    "    def predict(self, start=None, end=None):\n",
    "        # value extrapolated based on slope wrt first observation\n",
    "        # TODO: might be slightly wrong\n",
    "        # doesn't *quite* agree with R's RW(Y~drift()) ?\n",
    "        Y = self.y\n",
    "        Y0 = Y.values[0]\n",
    "        YT = Y.shift(-1)\n",
    "        start, end, index = self._normalize_times(start, end)\n",
    "        YT = pd.Series(np.nan, index=index)\n",
    "        YT.loc[Y.index.min():Y.index.max()] = Y\n",
    "        YT = YT.shift(1)\n",
    "        YT.iloc[0] = Y.iloc[0]\n",
    "        h = pd.Series(1, index=index)\n",
    "        extrap_mask = YT.isna()\n",
    "        h.loc[YT.isna()] = np.arange(1, extrap_mask.sum()+1)\n",
    "        YT.loc[extrap_mask] = Y.iloc[-1]\n",
    "        x = np.maximum(1, np.arange(len(YT)) - 1)\n",
    "        out = YT + h * ((YT - Y0) / x)\n",
    "        out.iloc[0] = np.nan\n",
    "        out = out.loc[start:].copy()\n",
    "        return out.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean Model\n",
    "* Just predict future as the mean of past values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m = TSMean(bricks.Bricks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(bricks.Bricks, color='k')\n",
    "ax.plot(m.forecast(end='2010'), color='C2', label='mean')\n",
    "ax.legend(**legend_right)\n",
    "ax.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Naive\n",
    "\n",
    "* Simply set all forecasts to be the value of the last observation\n",
    "$$\\hat{y}_{T+h|T} = y_{T}.$$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = TSNaive(bricks.Bricks).fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(bricks.Bricks, color='k')\n",
    "ax.plot(n.forecast(end='2010'), color='C0', label='naïve')\n",
    "ax.legend(**legend_right)\n",
    "ax.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Seasonal naive method\n",
    "* Each forecast will be equal to the last observed value from the same season\n",
    "$$\\hat{y}_{T+h|T} = y_{T+h-m(k+1)},$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s = TSNaiveSeasonal(bricks.Bricks, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(bricks.Bricks, color='k')\n",
    "ax.plot(s.forecast(end='2010'), color='C1', label='seasonal naïve')\n",
    "ax.legend(**legend_right)\n",
    "ax.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drift method\n",
    "* Method to capture the increase or decrease over time\n",
    "* Equivalent to drwaing a line between the first and last observations, and extrapolating it into the future\n",
    "\n",
    "$$ \\hat{y}_{T+h|T} = y_{T} + \\frac{h}{T-1}\\sum_{t=2}^T (y_{t}-y_{t-1}) = y_{T} + h \\left( \\frac{y_{T} -y_{1}}{T-1}\\right).$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dr = TSDrift(bricks.Bricks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(bricks.Bricks, color='k')\n",
    "ax.plot(dr.forecast(end='2010'), color='C3', label='drift')\n",
    "ax.legend(**legend_right)\n",
    "ax.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(bricks.Bricks, color='k')\n",
    "ax.plot(n.forecast(end='2010'), color='C0', label='naïve')\n",
    "ax.plot(s.forecast(end='2010'), color='C1', label='seasonal naïve')\n",
    "ax.plot(m.forecast(end='2010'), color='C2', label='mean')\n",
    "ax.plot(dr.forecast(end='2010'), color='C3', label='drift')\n",
    "ax.legend(**legend_right)\n",
    "ax.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Another example: Australian quarterly beer production"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y = aus_production.Beer\n",
    "Ytrain = Y[:'2006']\n",
    "m = TSMean(Ytrain)\n",
    "n = TSNaive(Ytrain).fit()\n",
    "s = TSNaiveSeasonal(Ytrain, 4)\n",
    "dr = TSDrift(Ytrain)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(Ytrain, 'k')\n",
    "ax.plot(Y, 'k:')\n",
    "ax.plot(n.forecast(end='2010'), color='C0', label='naïve')\n",
    "ax.plot(s.forecast(end='2010'), color='C1', label='seasonal naïve')\n",
    "ax.plot(m.forecast(end='2010'), color='C2', label='mean')\n",
    "ax.plot(dr.forecast(end='2010'), color='C3', label='drift')\n",
    "ax.legend(**legend_right)\n",
    "ax.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fitted values\n",
    "* How well the method fits the data\n",
    "* How well the mothod forecasts\n",
    "\n",
    "* $\\hat{y}_{t|t-1}$ is the forecast of $y_t$ based on observations $y_{1},\\dots,y_{t-1}$\n",
    "* We call these \"fitted values\"\n",
    "* Sometimes drop the subscript: $\\hat{y}_{t} = \\hat{y}_{t|t-1}$\n",
    "* $\\hat{y}_{t} = \\overline{y}_t$ for average method\n",
    "* $\\hat{y}_{t} = y_{t-1} + (y_t - y_1)/(T-1)$ for drift method"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Residuals\n",
    "\n",
    "* difference between observed value and its fitted value\n",
    "* Assumptions:\n",
    "    * $\\{e_t\\}$ uncorrelated. If they aren't, then information left in residuals that should be used in computing forecasts\n",
    "    * $\\{e_t\\}$ have mean zero. If they don't, then forecasts are biased\n",
    "* Useful properties (for distributions & prediction intervals\n",
    "    * $\\{e_t\\}$ have constant variance\n",
    "    * $\\{e_t\\}$ are normally distributed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GOOG = (\n",
    "    pd.read_csv('data/gafa_stock.csv')\n",
    "    .query(\"Symbol == 'GOOG'\")\n",
    "    .sort_values('Date')\n",
    "    .reset_index(drop=True)\n",
    "    .pipe(compute, lambda x: dict(Date = pd.to_datetime(x.Date, format='%Y-%m-%d')))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GOOG_2015 = GOOG.query('Date.dt.year == 2015')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(GOOG_2015)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y = GOOG.Close\n",
    "Ytrain = GOOG_2015.Close\n",
    "nsamples = len(GOOG_2015)\n",
    "m = TSMean(Ytrain)\n",
    "n = TSNaive(Ytrain).fit()\n",
    "s = TSNaiveSeasonal(Ytrain, nsamples - 2)\n",
    "dr = TSDrift(Ytrain)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m.predict()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(Y[GOOG.Date.between('2015-01-01', '2016-01-30')], color='k')\n",
    "c = 'C3 C2 C0 C4'.split()\n",
    "ax.plot(m.predict(),  ls='--', color=c[0])\n",
    "ax.plot(n.predict(),  ls='--', color=c[1])\n",
    "ax.plot(s.predict(),  ls='--', color=c[2])\n",
    "ax.plot(dr.predict(), ls='--', color=c[3])\n",
    "ax.plot(m.forecast(30),  color=c[0], label='Mean')\n",
    "ax.plot(n.forecast(30),  color=c[1], label='Naive')\n",
    "ax.plot(s.forecast(30),  color=c[2], label='Seasonal Naive')\n",
    "ax.plot(dr.forecast(30), color=c[3], label='Drift')\n",
    "ax.set(ylabel='Closing Price (USD)')\n",
    "ax.legend(loc='center left', bbox_to_anchor=[1, .5])\n",
    "suptitle('Google stock')\n",
    "ax.set(title='daily close thru Jan 2016')\n",
    "ax.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = GOOG_2015.assign(\n",
    "    mean=m.predict(),\n",
    "    naive=n.predict(),\n",
    "    naive_seasonal=s.predict(),\n",
    "    drift=dr.predict(),\n",
    "    resid_mean=m.predict() - Ytrain,\n",
    "    resid_naive=n.predict() - Ytrain,\n",
    "    resid_naive_seasonal=s.predict() - Ytrain,\n",
    "    resid_drift=dr.predict() - Ytrain,\n",
    ")\n",
    "results.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_tsresiduals(Y, y, acf_lags=np.r_[1:26]):\n",
    "    \"\"\"Plot timeseries residuals for ground truth Y and estimate y.\"\"\"\n",
    "    fig = plt.figure()\n",
    "    gs = plt.GridSpec(3, 2, figure=fig)\n",
    "    ts_ax = fig.add_subplot(gs[0, :])\n",
    "    axs = np.array([ts_ax] + [fig.add_subplot(gs[i, j]) for j in (0, 1) for i in (1, 2)])\n",
    "    ax, rax, hax, acfax, pacfax = axs\n",
    "    mask = ~(np.isnan(Y) | np.isnan(y))\n",
    "    Y, y = Y[mask], y[mask]\n",
    "    dy = Y - y\n",
    "    ax.plot(Y, color='k')\n",
    "    ax.plot(y)\n",
    "    ax.set(title='Time Series')\n",
    "    lim = 1.1 * max(-dy.min(), dy.max())\n",
    "    lim = -lim, lim\n",
    "    rax.plot(dy)\n",
    "    rax.set(ylim=lim, title='Residuals')\n",
    "    sns.histplot(dy, bins=np.linspace(lim[0], lim[1], 22),\n",
    "             kde=True, stat='density', ax=hax)\n",
    "    hax.set(title='Residual Distribution')\n",
    "    sm.graphics.tsa.plot_acf(dy, lags=acf_lags, ax=acfax)\n",
    "    acfax.set_ylim(-0.5, 0.5)\n",
    "    sm.graphics.tsa.plot_pacf(dy, lags=acf_lags, ax=pacfax)\n",
    "    pacfax.set_ylim(-0.5, 0.5)\n",
    "    for a in axs.ravel():\n",
    "        a.grid()\n",
    "    plt.tight_layout()\n",
    "    return fig, axs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_tsresiduals(Ytrain, results.naive)\n",
    "suptitle('Naïve forecast')\n",
    "plt.subplots_adjust(top=.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_tsresiduals(Ytrain, results.drift)\n",
    "suptitle('Naïve forecast')\n",
    "plt.subplots_adjust(top=.9)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forecast Distributions\n",
    "\n",
    "* All forecasts have an uncertainty\n",
    "* We express the uncertainty in our forecasts using a probability distribution\n",
    "* Describes the probability of observing possible future values using the fitted model\n",
    "* Most time series models produce normally distributed forecasts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction intervals\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mult = pd.DataFrame(dict(Percentage=np.r_[50:90:5, 90:100]))\n",
    "mult['Multiplier'] = stats.norm.isf((1 - mult.Percentage/100) / 2)\n",
    "mult = mult.set_index('Percentage')\n",
    "mult"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "g = GOOG[GOOG.Date.lt('2016-02-01')]\n",
    "ax.plot(GOOG_2015.Close, color='.3', zorder=-10, label='data')\n",
    "fc = n.forecast(10)\n",
    "ax.plot(fc, lw=1.5, label='naïve forecast')\n",
    "sigma = results.resid_naive.std()\n",
    "m80, m95 = mult.Multiplier.loc[[80, 95]]\n",
    "didx = fc.index - fc.index.min()\n",
    "ax.fill_between(fc.index, fc - m80*sigma * np.sqrt(didx), fc + m80*sigma * np.sqrt(didx),\n",
    "                alpha=.33, lw=0, label='80%')\n",
    "ax.fill_between(fc.index, fc - m95*sigma * np.sqrt(didx), fc + m95*sigma * np.sqrt(didx),\n",
    "                alpha=.25, color='C0', lw=0, label='95%')\n",
    "ax.legend(loc='center left', bbox_to_anchor=[1, .5])\n",
    "suptitle('Google stock')\n",
    "ax.set(title='daily close thru Jan 2016', ylabel='Closing Price (USD)')\n",
    "ax.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forecasting with decomposition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d = pd.read_csv('data/us_employment.csv')\n",
    "d = us_retail_employment = (\n",
    "    d\n",
    "    .assign(date=pd.to_datetime(d.Month, format='%Y %b'))\n",
    "    .pipe(compute, lambda x: dict(year=x.date.dt.year))\n",
    "    .query(\"year >= 1990 and Title == 'Retail Trade'\")\n",
    "    .set_index('date')\n",
    "    .drop(columns='year Series_ID'.split())\n",
    ")\n",
    "us_retail_employment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stl = sm.tsa.STL(d.Employed).fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s_stl = TSNaiveSeasonal(stl.seasonal, 12)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dr_stl = TSDrift(d.Employed - stl.seasonal)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "end = us_retail_employment.index.max() + + timedelta(days=365*4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=sizets)\n",
    "ax.plot(d.Employed, 'k')\n",
    "end = pd.to_datetime('2025-01-01')\n",
    "ax.plot(s_stl.predict(end=end) + dr_stl.predict(end=end))\n",
    "ax.plot(s_stl.forecast(end=end) + dr_stl.forecast(end=end))\n",
    "ax.set(ylabel='Employed')\n",
    "ax.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_tsresiduals(d.Employed, s_stl.predict() + dr_stl.predict());"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating forecast accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aus_production['1995':]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aus_production[aus_production.index.quarter == 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aus_production.iloc[-20:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recent_production = aus_production['1992':]\n",
    "split = '2007-12-01'\n",
    "beer_train = recent_production[:split]\n",
    "beer_test = recent_production[split:]\n",
    "\n",
    "Ytrain = beer_train.Beer\n",
    "ms = dict(\n",
    "    Drift = TSDrift(Ytrain),\n",
    "    Mean = TSMean(Ytrain),\n",
    "    Naive = TSNaive(Ytrain),\n",
    "    SeasonalNaive = TSNaiveSeasonal(Ytrain, 4),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Y = recent_production.Beer\n",
    "ax.plot(Y, color='k')\n",
    "c = 'C3 C2 C0 C4'.split()\n",
    "for ((label, model), c) in zip(ms.items(), c):\n",
    "    ax.plot(model.predict(),  ls=':', color=c, alpha=.5)\n",
    "    ax.plot(model.forecast(end=Y.index.max()),  color=c, label=label)\n",
    "ax.set(ylabel='Megalitres')\n",
    "ax.legend(loc='center left', bbox_to_anchor=[1, .5])\n",
    "suptitle('Google stock')\n",
    "ax.set(title='Forecasts for quarterly beer production')\n",
    "ax.grid()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def MAE(Y, y):\n",
    "    \"\"\"Mean absolute error.\"\"\"\n",
    "    return np.mean(np.abs(Y - y))\n",
    "\n",
    "\n",
    "def MAPE(Y, y):\n",
    "    \"\"\"Mean absolute percent error.\"\"\"\n",
    "    return 100 * np.mean(np.abs((Y - y) / Y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tsaccuracy(Ytest, models):\n",
    "    \"\"\"Gather some metrics for a few models.\"\"\"\n",
    "    fs = RMSE, MAE, MAPE\n",
    "    return pd.DataFrame({\n",
    "        label: [f(Ytest, model.predict(Ytest.index.min(), Ytest.index.max()))\n",
    "                for f in (RMSE, MAE, MAPE)]\n",
    "        for (label, model) in models.items()\n",
    "    }, index=[f.__name__ for f in fs]).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsaccuracy(beer_test.Beer, ms)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results.naive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
